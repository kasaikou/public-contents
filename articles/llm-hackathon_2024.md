---
title: LLM の効果的な社会実装 【社内生成 AI ハッカソン】
emoji: 🔨
type: idea
topics: [LLM, 大規模言語モデル, ハッカソン]
published: false
---

# まえがき

かくかくしかじかあり、社内生成 AI ハッカソンでプロダクトを作ることになりました。ワタシ個人としては、ちゃんと LLM を使ったプロダクトになりうるものを作ったことはなかったので、そこで感じたことや思ったことを書いていこうかなと思います。

ということで、今回は珍しく社内での話を書こうかなと思ったので書くことにしました。
とは言ってもきっかけが社内というだけで、ワタシ自身は好き勝手書こうかなと思っています。

:::message alert

- ワタシ自身の個人的な持論であるということを念頭に置いていただければなと思います。
- Terraform で作成したプロダクトおよび展開した AWS リソースは LLM ハッカソン発表後に破棄しました。

:::

# 今回作成したプロダクト

LLM ハッカソンで作成したプロダクトは、質問者の知識の度合いを基に発表時の登壇原稿から想定質問を考えてもらうサービスです。

この辺の細かい説明はスライドを読んだ方が早いかもしれないです。

@[speakerdeck](30db4c9c3959425a9efab94608f11453)

スライドを作る際、自分で作っている分には必要なところを説明したと思っている一方で、発表をすればなんらかの質問が出てくると思うのですが、あらかじめ想定質問を自分で考えるのは難しいと考えています。

一方で、質問を考える際、質問者は自分が持っている知識をベースに質問するので、 LLM にその人の持っている知識をシミュレートしてもらうことでより的確な想定質問を検討することができます。

## 技術的な話

今回は下図のように、 AWS 上にリソースを展開して作成しました。リソースの展開は Terraform で行っていました。

![](https://storage.googleapis.com/zenn-user-upload/e4eed1f61f96-20240618.png)

Amazon Bedrock 上の Claude 3 haiku を使用しました。今回はスループット優先にしたので LLM の性能自体はさほど高くはないです。また、 us-east-1 リージョンでしか使えないので、面倒になって他のリソースも全て us-east-1 リージョンで作成しました。

Amazon Transcribe がリアルタイムではなく、バッチ処理になっているのは単純にリアルタイム処理を実装する余裕がチーム内でなかったためです。終了間際にワタシが言い出したことなので、実装者には感謝するしかないです。

# LLM （ひいては生成 AI 全般）に対して思うこと

:::message

ワタシ個人の感想です（N回目）。

:::

ワタシ自身、生成 AI に関しては便利なものは使えばいいんじゃない？くらいのスタンスをかましています。
その上で、今の生成 AI はあまりにも汎用的すぎてどのように使えばいいのかわからず使いやすいとは言い難いのが現状なのかな、と思っています。

そこで、今回作ったプロダクトでは単純な操作で具体的な目的が伴うような機能に絞ることで扱いやすくしました。

また、今回プロダクトを作るにあたって、「LLMを使っている」、という雰囲気にしないことを重視して作りました。そのために、想定質問者ごとに個性をつけたり、UI に配慮することで LLM を使っている感を減らしてみました。

もう少し書きたいことがあった気がしたのですが、思い出せないので思い出したらまた別の記事にします。
